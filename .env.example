
# Environment Configuration
NODE_ENV=development
PORT=3000

# LLM Client Configuration
# Choose your LLM provider: gemini, ollama
LLM_CLIENT_TYPE=ollama

# Google OAuth Configuration
GOOGLE_CLIENT_ID=your_google_client_id_here
GOOGLE_CLIENT_SECRET=your_google_client_secret_here
JWT_SECRET=secret_jwt_key_here

# Gemini AI Configuration (if using LLM_CLIENT_TYPE=gemini)
GEMINI_API_KEY=gemini_api_key_here

# Ollama Configuration (if using LLM_CLIENT_TYPE=ollama)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=mistral:latest

# Add this to your .env file
DATABASE_URL=postgresql_url_here

# GitHub Integration (when we add it)
GITHUB_CLIENT_ID=github_client_id_here
GITHUB_CLIENT_SECRET=github_client_secret_here
GITHUB_REDIRECT_URI=http://localhost:3000/api/github/callback



# CORS Configuration (keep this for backend security)
ALLOWED_ORIGINS=http://localhost:4200,http://localhost:3000

# Security Configuration
RATE_LIMIT_WINDOW_MS=900000
RATE_LIMIT_MAX_REQUESTS=100

# File Upload Configuration
MAX_FILE_SIZE=

UPLOAD_PATH=./uploads
GENERATED_PATH=./generated

# File Cleanup Configuration
UPLOADS_MAX_AGE_HOURS=24
UPLOADS_MAX_FILES=1000
UPLOADS_CLEANUP_INTERVAL_HOURS=4
GENERATED_MAX_AGE_DAYS=30
GENERATED_MAX_FILES=500
GENERATED_CLEANUP_INTERVAL_HOURS=12
ORPHANED_CHECK_INTERVAL_HOURS=24
MAX_SESSIONS_PER_USER=50

INTERNAL_PROCESSING_TOKEN=internal_processing_token_here


# LLM Client Configuration Notes:
# 
# For Gemini (recommended for production):
# 1. Get API key from: https://makersuite.google.com/app/apikey
# 2. Set LLM_CLIENT_TYPE=gemini
# 3. Set GEMINI_API_KEY=your_actual_key
#
# For Ollama (local development, no API costs):
# 1. Install Ollama: https://ollama.ai/
# 2. Pull a model: ollama pull llama2
# 3. Set LLM_CLIENT_TYPE=ollama
# 4. Optionally set OLLAMA_BASE_URL and OLLAMA_MODEL
# 5. Make sure Ollama is running: ollama serveINTERNAL_PROCESSING_TOKEN=dev_token_12345
